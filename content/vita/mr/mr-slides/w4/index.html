<!DOCTYPE html>
<html>
  <head>
    <title>Uncertainty and significance testing</title>
    <meta charset="utf-8">
    <meta name="author" content="Daniel Anderson" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/uo.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/uo-fonts.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/hygge.css" rel="stylesheet" />
    <link rel="stylesheet" href="custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Uncertainty and significance testing
### Daniel Anderson
### Week 4

---




# Agenda 
* A little bit of R
  + Load some data
  + radiant demo
* Uncertainty 
  + Standard errors
  + Confidence intervals 
  + p-values
* Sample interpretations
* Lab

---
# Thinking about learning objectives
I would really like you to leave this class being able to do the following:
1. Read in data to R
1. Produce some basic visualizations of the data
  + Distributions, scatterplots with linear models overlaid, boxplots, barplots


--
### Regression models
.pull-left[
Fit linear regression models with
  + continuous and categorical variables
  + interactions
]
.pull-right[
Interpret models correctly
  + coefficients
  + model `\(R^2\)`
  + SEs, CIs, and significance
]

---
class: inverse middle center
background-image:url(../img/chalkboard.jpg)
background-size:cover

# What questions do you have?

---
# First thing's first
Let's get some data!

[demo]

Please follow along. We'll load the `hsb2.sav` file.




---
# Variance of the estimate
Recall the residual standard error 

.Large[
$$
s\_{y.x} = \sqrt{\frac{\sum (Y - Y')^2}{df}} =  \sqrt{\frac{ss_{res}}{df}}
$$

$$
df = n - k - 1
$$

]


--
* A quick note on notation
  + When we use `arm::display()` it reports `\(k\)` as the number of estimated
    parameters. (this is pretty standard and actually what I usually use)
  + Pedhazur uses `\(k\)` to indicate the number of *predictors* in the model
  + I'll stick with Pedhazur's even though it's a little unnatural for me.

---
## In the simple linear regression case
* The standard error of `\(b\)` is

.Large[
$$
s\_b = \frac{s\_{y.x}}{\sqrt{\sum x^2}}
$$
]


--
In words... the model residual standard error divided by the (square root of
the) sum of the squared deviations

--
### Quick verification
.gray[Do it with me!]

* First, let's fit a model with students' reading scores predicting their
mathematics scores. 

---


```r
m1 &lt;- lm(math ~ read, d)
```

--


```r
arm::display(m1, detail = TRUE)
```

```
## lm(formula = math ~ read, data = d)
##             coef.est coef.se t value Pr(&gt;|t|)
## (Intercept) 21.04     2.59    8.12    0.00   
## read         0.61     0.05   12.44    0.00   
## ---
## n = 200, k = 2
## residual sd = 7.04, R-Squared = 0.44
```

* Let's interpret the results

---
# Confirm

.Large[
$$
s\_b = \frac{s\_{y.x}}{\sqrt{\sum x^2}}
$$
]

--

* We'll focus on calculating the denominator, and we'll just plug-in the
numerator. 

--
* What's the sum of squares again?

---
First, calculate the deviations (note - we're creating a new variable, `dev`,
  then selecting our original `read` variable and `dev` only).


```r
mean(d$read)
```

```
## [1] 52.23
```

```r
ss &lt;- d %&gt;%
  select(read)

ss %&gt;%
* mutate(dev = read - mean(read)) %&gt;%
  head()
```

```
## # A tibble: 6 x 2
##    read        dev
##   &lt;dbl&gt;      &lt;dbl&gt;
## 1    57   4.77    
## 2    68  15.77    
## 3    44  -8.230000
## 4    63  10.77    
## 5    47  -5.230000
## 6    44  -8.230000
```

---
# Square the deviations


```r
ss %&gt;%
  mutate(dev = read - mean(read),
*        dev2 = dev^2) %&gt;%
  head()
```

```
## # A tibble: 6 x 3
##    read        dev      dev2
##   &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;
## 1    57   4.77      22.7529 
## 2    68  15.77     248.6929 
## 3    44  -8.230000  67.73290
## 4    63  10.77     115.9929 
## 5    47  -5.230000  27.35290
## 6    44  -8.230000  67.73290
```

---
# Sum the squared deviations


```r
ss %&gt;%
  mutate(dev = read - mean(read),
         dev2 = dev^2,
*        sum_squares = sum(dev2)) %&gt;%
  head()
```

```
## # A tibble: 6 x 4
##    read        dev      dev2 sum_squares
##   &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;
## 1    57   4.77      22.7529     20919.42
## 2    68  15.77     248.6929     20919.42
## 3    44  -8.230000  67.73290    20919.42
## 4    63  10.77     115.9929     20919.42
## 5    47  -5.230000  27.35290    20919.42
## 6    44  -8.230000  67.73290    20919.42
```

---
# Square Root


```r
ss %&gt;%
  mutate(dev = read - mean(read),
         dev2 = dev^2,
         sum_squares = sum(dev2),
*        denom = sqrt(sum_squares)) %&gt;%
  head()
```

```
## # A tibble: 6 x 5
##    read        dev      dev2 sum_squares    denom
##   &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;
## 1    57   4.77      22.7529     20919.42 144.6355
## 2    68  15.77     248.6929     20919.42 144.6355
## 3    44  -8.230000  67.73290    20919.42 144.6355
## 4    63  10.77     115.9929     20919.42 144.6355
## 5    47  -5.230000  27.35290    20919.42 144.6355
## 6    44  -8.230000  67.73290    20919.42 144.6355
```

---
# SE estimate


```r
7.04 / 144.6355
```

```
## [1] 0.04867408
```

```r
arm::display(m1, digits = 4, detail = TRUE)
```

```
## lm(formula = math ~ read, data = d)
##             coef.est coef.se t value Pr(&gt;|t|)
## (Intercept) 21.0382   2.5894  8.1246  0.0000 
## read         0.6051   0.0487 12.4378  0.0000 
## ---
## n = 200, k = 2
## residual sd = 7.0371, R-Squared = 0.44
```

---
# In the MR case
* We have to remove the shared variance

.Large[
$$
s\_{b\_{y1.2}} = \frac{s\_{y.x}}{\sqrt{\sum x\_1^2(1-r\_{x\_1x\_2}^2)}}
$$
]

---
# Quick verification

Let's fit a second model, this time with reading and writing predicting
students' math scores

--


```r
m2 &lt;- lm(math ~ read + write, d)
arm::display(m2, detail = TRUE, digits = 4)
```

```
## lm(formula = math ~ read + write, data = d)
##             coef.est coef.se t value Pr(&gt;|t|)
## (Intercept) 12.8651   2.8216  4.5595  0.0000 
## read         0.4169   0.0565  7.3817  0.0000 
## write        0.3411   0.0611  5.5832  0.0000 
## ---
## n = 200, k = 3
## residual sd = 6.5553, R-Squared = 0.52
```

---

```r
arm::display(m2, digits = 4, detail = TRUE)
```

```
## lm(formula = math ~ read + write, data = d)
##             coef.est coef.se t value Pr(&gt;|t|)
## (Intercept) 12.8651   2.8216  4.5595  0.0000 
## read         0.4169   0.0565  7.3817  0.0000 
## write        0.3411   0.0611  5.5832  0.0000 
## ---
## n = 200, k = 3
## residual sd = 6.5553, R-Squared = 0.52
```

```r
# Compute correlation
x1x2_cor &lt;- cor(d$read, d$write)

# Compute sums-of squares for reading (in a single line of code)
ss_read &lt;- sum((d$read - mean(d$read))^2)

6.5553 / sqrt(ss_read*(1 - x1x2_cor^2))
```

```
## [1] 0.05648365
```

---
# Challenge
Can you calculate the standard error for `write` by hand? 

Follow these steps:
1. Compute the correlation, as in the prior slide
2. Compute the sums of squares for `write`
3. Use the code we used before `6.555315 / sqrt(ss_read*(1 - x1x2_cor^2))`,
   but insert your sums of squares estimate.

---
# What is the standard error?

--
The variance of the estimate (standard deviation) over (theoretically) repeated
samples. 


--
.Large[üßê]

---
# Simulating the process

[demo]

Note - this is purely for demonstration. Please DO NOT follow along. If you're
interested in the code, play with it after class and we can chat if you want.


--
### Bootstrapping

![](../img/bootstrap.png)


---

.code-bg-red[


```r
set.seed(8675309)
samples &lt;- replicate(1000, 
                     d[sample(1:nrow(d),
                              size = nrow(d),
                              replace = TRUE), ],
                     simplify = FALSE)
```
]

---
# First 4 rows of first 2 datasets

.code-bg-red[


```r
map(samples[1:2], ~head(., 4))
```

```
## [[1]]
## # A tibble: 4 x 11
##      id race     ses   schtyp prog   read write  math science socst Gender
##   &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; 
## 1   103 white    high  public acad‚Ä¶    76    52    64      64    61 Male  
## 2   173 white    low   public gene‚Ä¶    50    62    61      63    51 Female
## 3   138 white    midd‚Ä¶ public voca‚Ä¶    43    57    40      50    51 Female
## 4    10 hispanic midd‚Ä¶ public gene‚Ä¶    47    54    49      53    61 Female
## 
## [[2]]
## # A tibble: 4 x 11
##      id race  ses    schtyp  prog    read write  math science socst Gender
##   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; 
## 1    71 white middle public  gener‚Ä¶    57    62    56      58    66 Female
## 2    26 asian high   public  acade‚Ä¶    60    59    62      61    51 Female
## 3   195 white middle private gener‚Ä¶    57    57    60      58    56 Male  
## 4   170 white high   public  acade‚Ä¶    47    62    61      69    66 Male
```

]

---
# Fit a model to each sample

.code-bg-red[


```r
models &lt;- map(samples, ~lm(math ~ read + write, .))
```

]

---

.code-bg-red[


```r
boot_ests &lt;- map_df(models, 
                    ~data.frame(coef = coef(.),
                                param = c("intercept",
                                          "b1_read",
                                          "b2_write")), 
                    .id = "iteration") %&gt;% 
  spread(param, coef) %&gt;%
  mutate(iteration = as.numeric(iteration)) %&gt;%
  arrange(iteration)
head(boot_ests, 4)
```

```
##   iteration   b1_read  b2_write intercept
## 1         1 0.4832635 0.3583211   8.71417
## 2         2 0.4130313 0.3186412  14.64451
## 3         3 0.4705402 0.3276435  10.79783
## 4         4 0.3903003 0.3739700  12.73905
```
]


---
# Visualizing the estimates

.code-bg-red[

![](w4_files/figure-html/visualize-uncertainty-1.png)&lt;!-- --&gt;
]

---
# Calculating the standard errors

.code-bg-red[


```r
boot_ests %&gt;% 
  summarize(int_sd = sd(intercept),
            b1_sd  = sd(b1_read),
            b2_sd  = sd(b2_write))
```

```
##     int_sd      b1_sd      b2_sd
## 1 2.620572 0.05793157 0.06139615
```
]

---
## Looking back at our parametric estimates


```r
arm::display(m2, digits = 4)
```

```
## lm(formula = math ~ read + write, data = d)
##             coef.est coef.se
## (Intercept) 12.8651   2.8216
## read         0.4169   0.0565
## write        0.3411   0.0611
## ---
## n = 200, k = 3
## residual sd = 6.5553, R-Squared = 0.52
```


---
# Another visualization
(This one is with simple linear regression)

.code-bg-red[

.pull-left[

![](w4_files/figure-html/slope-vis1-1.png)&lt;!-- --&gt;

]
]

.pull-right[

![](w4_files/figure-html/slope-vis2-1.png)&lt;!-- --&gt;

]


---
class: inverse middle center
background-image:url(../img/celebrate.jpg)
background-size:cover

# Testing for significance


---
# The `\(t\)` statistic
* The coefficients, divided by their standard error, provides a `\(t\)`-distributed
statistic.

--

  + What's the difference between a `\(t\)` distribution and a normal distribution?

---
![](w4_files/figure-html/t-normal1-1.png)&lt;!-- --&gt;

---
# Fat tails
* When the `\(df\)` are small, the tails are fatter
* This implies you need a bigger `\(t\)` to reach `\(p &lt; 0.05\)`


---
![](w4_files/figure-html/t-normal2-1.png)&lt;!-- --&gt;

---
# Practical takeaways
1. The size of the SE will depend on `\(n\)` because 
`\(s_{y.x} = \sqrt{\frac{ss_{res}}{df}}\)` and `\(df = n - k - 1\)` 

--
1. The size of the SE will depend on the fit to the data because better fit =
smaller `\(ss_{res}\)`

--
1. Because `coef/se = t`, larger standard errors will result in smaller `\(t\)`
statistics.

--
1. Smaller sample sizes also require larger `\(t\)` to be significant


--
### How do you get a larger `\(t\)`

--
Account for more variance (bigger effect size), smaller standard errors, bigger
`\(n\)`

---
# Overall model test
* The model `\(R^2\)` represents the proportion the residual variance has been
reduced.

.large[
$$
R^2 = \frac{SS\_{reg}}{SS\_{y}}
$$
]

* Often we want to know if this reduction is significantly different than zero.
  We can evaluate this using an `\(F\)` test.

--

.pull-left[
Using `\(R^2\)`
.large[
$$
F = \frac{R^2/k}{(1-R^2)/(n - k - 1)}
$$
]
]

.pull-right[
or using the sums of squares

.large[
$$
F = \frac{SS\_{reg}/df\_{reg}}{SS\_{res}/df\_{res}}
$$
]
]

---
class: middle right
background-image: url(https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/F-distribution_pdf.svg/325px-F-distribution_pdf.svg.png)
background-size:contain

# F Distribution

---
# Pop quiz

Can the model `\(R^2\)` be significant even if **none** of the individual
coefficients are?

--
### Of course!

&lt;div align = "center"&gt;
&lt;img src = ../img/high-collinearity.png height = 300&gt;
&lt;/div&gt;

.footnote[Figure from Tu, Kellett, Clerehugh, &amp; Gilthorpe (2005): 
  https://www.nature.com/articles/4812743.pdf?origin=ppub]

---
class: inverse center
background-image:url(https://pics.me.me/overconfidence-this-is-going-to-end-in-disaster-and-you-31404205.png)
background-size:cover

# Confidence intervals

--

Almost always preferable to p-values alone


---
# How do we calculate 95% CIs?
* Practically: `\(b \pm 2*s_b\)`

--
* Why `\(2*s_b\)`?


--
### Actually:

.Large[
$$
b \pm t\_{(\frac{\alpha}{2},df)}s\_b
$$
]

---
# Approximating example


```r
arm::display(m2, digits = 4, detail = TRUE)
```

```
## lm(formula = math ~ read + write, data = d)
##             coef.est coef.se t value Pr(&gt;|t|)
## (Intercept) 12.8651   2.8216  4.5595  0.0000 
## read         0.4169   0.0565  7.3817  0.0000 
## write        0.3411   0.0611  5.5832  0.0000 
## ---
## n = 200, k = 3
## residual sd = 6.5553, R-Squared = 0.52
```

--

.pull-left[

```r
12.8651 - 2*2.8216
```

```
## [1] 7.2219
```

```r
12.8651 + 2*2.8216
```

```
## [1] 18.5083
```
]


--


.pull-right[

```r
confint(m2)
```

```
##                 2.5 %     97.5 %
## (Intercept) 7.3006103 18.4295249
## read        0.3055581  0.5283391
## write       0.2206314  0.4616124
```
]

---
The `qt` function returns the exact `\(t\)` value, which in this case is -1.972079. Compare that to a `\(Z\)` value, of -1.959964 (because we have 197 `\(df\)`).

--

.pull-left[
.code-bg-red[

```r
12.8651 + qt(0.05/2, 197)*2.8216
```

```
## [1] 7.300682
```

```r
12.8651 - qt(0.05/2, 197)*2.8216
```

```
## [1] 18.42952
```
]
]


.pull-right[

```r
confint(m2)
```

```
##                 2.5 %     97.5 %
## (Intercept) 7.3006103 18.4295249
## read        0.3055581  0.5283391
## write       0.2206314  0.4616124
```
]


---
## Want it to match **exactly** exactly?



```r
confint(m2)
```

```
##                 2.5 %     97.5 %
## (Intercept) 7.3006103 18.4295249
## read        0.3055581  0.5283391
## write       0.2206314  0.4616124
```
.code-bg-red[

```r
coef(m2)[2] + qt(0.025, m2$df.residual)* summary(m2)$coefficients[2, 2]
```

```
##      read 
## 0.3055581
```

```r
coef(m2)[2] + qt(0.975, m2$df.residual)* summary(m2)$coefficients[2, 2]
```

```
##      read 
## 0.5283391
```
]

---
# Using the bootstrap estimates

.code-bg-red[

```r
boot_ests %&gt;% 
  summarize(int_lower = quantile(intercept, 0.025),
            int_upper = quantile(intercept, 0.975),
            b1_lower = quantile(b1_read, 0.025),
            b1_upper = quantile(b1_read, 0.975),
            b2_lower = quantile(b2_write, 0.025),
            b2_upper = quantile(b2_write, 0.975))
```

```
##   int_lower int_upper  b1_lower  b1_upper  b2_lower  b2_upper
## 1  7.714023  18.26199 0.3035328 0.5277044 0.2214116 0.4611397
```
]

---
# How do we interpret these?

If your model is correct, the interval will contain the true population value
95% of the time.

--

### Not probability-based
* Frequentist stats (which this is) assumes a single "true" population value.
* Our CI comes from the estimated sampling distribution for the point estimate.
* Probability of the "true" value lying within those bounds is 0/1
* Thus, literally, "confidence" based - the wider the interval, the more
confident we can be. 

---
# p values
* A very similar process can be used to estimate the exact p value 


--
### What does a p-value represent?

&gt; the probability of obtaining data as extreme, or more extreme, than those 
  observed if the null hypothesis is correct and the model assumptions are met.



--
* If the value is outside the alpha level, it is "significant"
  + i.e., we can claim that the observed result is unlikely due to random
    sampling variability

---
# But
* The prior slide holds **only if we meet our model-assumptions**
  + If you don't meet your model assumptions, this is usually what gets messed
    up first.

---
# Before we move on
* This discussion is fairly technical and meant as background
  + e.g., "Where do these numbers actually come from?"

--
* Practically, you should be able to
  + Find and interpret SEs
  + Estimate and interpret CIs
  + Correctly interpret *p* values


--
### Let's practice

---
# Fit the corresponding model
$$
read_i = b_0 + b_1(SES_i) + b_2(math_i) + e
$$

Discuss at your table:
* What do the coefficients represent
* What does the standard error for math represent?
* What does the standard error for the SES-low represent?
* Interpret the p-values for the SES coefficients
* Estimate and interpret the 95% CIs for the model

---

```r
d &lt;- d %&gt;%
  mutate(ses = factor(ses))

m3 &lt;- lm(read ~ ses + math, d)
arm::display(m3, detail = TRUE)
```

```
## lm(formula = read ~ ses + math, data = d)
##             coef.est coef.se t value Pr(&gt;|t|)
## (Intercept) 17.87     3.52    5.07    0.00   
## seslow      -3.41     1.56   -2.19    0.03   
## sesmiddle   -2.20     1.30   -1.70    0.09   
## math         0.69     0.06   11.44    0.00   
## ---
## n = 200, k = 4
## residual sd = 7.64, R-Squared = 0.45
```

```r
confint(m3)
```

```
##                  2.5 %     97.5 %
## (Intercept) 10.9203275 24.8141011
## seslow      -6.4794276 -0.3358015
## sesmiddle   -4.7509137  0.3584140
## math         0.5692058  0.8063016
```

---
class: inverse center middle

# Lab
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "atelier-dune-light",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
