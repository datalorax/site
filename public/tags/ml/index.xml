<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ML on Data Science in Education</title>
    <link>https://www.datalorax.com/tags/ml/</link>
    <description>Recent content in ML on Data Science in Education</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>Daniel Anderson</copyright>
    <lastBuildDate>Fri, 22 May 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://www.datalorax.com/tags/ml/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Exploring Gradient Descent</title>
      <link>https://www.datalorax.com/post/exploring-gradient-descent/</link>
      <pubDate>Fri, 22 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.datalorax.com/post/exploring-gradient-descent/</guid>
      <description>tl;dr I&amp;rsquo;ve recently learned a lot about gradient descent, and wanted to share here. I used gradient descent to estimate linear regression models and, by the end, produce gifs like this, showing how the algorithm learns!
Intro This term I&amp;rsquo;m co-teaching an applied machine learning course in R using the {tidymodels} suite of packages. It&amp;rsquo;s been a great experience because it&amp;rsquo;s allowed me to dig into topics more deeply than I have previously, and it&amp;rsquo;s definitely helped me learn and understand the tidymodels infrastructure better.</description>
    </item>
    
  </channel>
</rss>
