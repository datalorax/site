<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Data Science in Education</title>
    <link>/post/</link>
    <description>Recent content in Posts on Data Science in Education</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>Daniel Anderson</copyright>
    <lastBuildDate>Fri, 30 Aug 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Creating bivariate color palettes</title>
      <link>/post/creating-bivariate-color-palettes/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/creating-bivariate-color-palettes/</guid>
      <description>I&amp;rsquo;m taking some time off work this week to be with my two girls in their final week of summer. But in that time I started playing around with colors in R a bit and wanted to share some of what I&amp;rsquo;ve learned, specifically in relation to bivariate color palettes. There is an existing R package, {biscale}, which is probably the simplest way to approach this, but I wanted to dig in a bit more and explore on my own.</description>
    </item>
    
    <item>
      <title>Exploring Geographic Variation in Achievement Gaps</title>
      <link>/post/exploring-geographic-variation-in-achievement-gaps/</link>
      <pubDate>Fri, 16 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/exploring-geographic-variation-in-achievement-gaps/</guid>
      <description>This is, basically, the third post in a series of posts about estimating and, now, exploring achievement gap variation between schools. The first post described the method, while the second applied the method to estimate achievement gaps for all schools reporting data on students coded as Hispanic and White in California. That post included some preliminary explorations of the data, but this post will take that further by looking at the variance geographically.</description>
    </item>
    
    <item>
      <title>Applying V to study achievement gaps</title>
      <link>/post/applying-v-to-study-achievement-gaps/</link>
      <pubDate>Tue, 06 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/applying-v-to-study-achievement-gaps/</guid>
      <description>In the last post I talked about one method to estimate distributional differences from ordinal data, such as those reported by statewide accountability systems. In this post, we&amp;rsquo;ll put this method to work for the state of California. I&amp;rsquo;ll show how we can estimate school-level Hispanic/White achievement gaps for every school in the state that reports data on both groups. In California, this means the school must have at least 30 students in each group, for the corresponding grade.</description>
    </item>
    
    <item>
      <title>Estimating important things with public data</title>
      <link>/post/estimating-important-things-with-public-data/</link>
      <pubDate>Mon, 29 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/estimating-important-things-with-public-data/</guid>
      <description>Intro One of the neatest things I&amp;rsquo;ve learned about in the last few years is how to estimate effect sizes from coarsened data. The original article discussed using the method with publicly available data reported by statewide education agencies, and that&amp;rsquo;s the approach I&amp;rsquo;ll use here too. But more generally, the method could be applied in any situation in which a continuous distribution is reported out in ordinal bins.
Background In case you&amp;rsquo;re unfamiliar, states administer tests to students at the end of the year in each of Grades 3-8, and once in high school, for all students in their state in English/Language Arts and Mathematics.</description>
    </item>
    
    <item>
      <title>Looking into #KeepFamiliesTogether</title>
      <link>/post/looking-into-keepfamiliestogether/</link>
      <pubDate>Tue, 19 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/looking-into-keepfamiliestogether/</guid>
      <description>This week I&amp;rsquo;m at the Seattle branch of the Summer Institute on Computational Social Science. Today, we discussed digital trace data and spent some time thinking about different sources of digital trace data. One of the easiest sources is twitter, and thanks to Mike Kearney, it&amp;rsquo;s easily accessible in R via the {rtweet} package!
I joined a group addressing a topic I find myself dwelling on throughout the day - the immigration crisis at the border.</description>
    </item>
    
    <item>
      <title>Peeking behind the curtain with {slidex}</title>
      <link>/post/peeking-behind-the-curtain-with-slidex/</link>
      <pubDate>Fri, 08 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/peeking-behind-the-curtain-with-slidex/</guid>
      <description>I gave a lightning talk (slides here) this past weekend at the second annual Cascadia R Conference that was focused on creating and contributing new themes to the {xaringan} package, which is essentially a really well thought out and well-organized R Markdown wrapper around the remark.js package for producing beautiful HTML slides. At the end of that talk, I announced the work-in-progress version of my new R package, {slidex}, for converting Microsoft PowerPoint slides to R Markdown, and specifically {xaringan}, with a single function.</description>
    </item>
    
    <item>
      <title>Writing an R Package Basics (and why I think you should)</title>
      <link>/post/why-i-think-you-should-write-an-r-package/</link>
      <pubDate>Tue, 24 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/why-i-think-you-should-write-an-r-package/</guid>
      <description>On April 10, 2018, I gave a talk entitled Developing your first R package: A case study with esvis for the Eugene R Users Group. Although I discussed my esvis package, the focus of the talk was really on tools and tips for developing R pacakges. In this post, I&amp;rsquo;ll go over some of the content in that talk, and discuss why I think you should develop an R package.</description>
    </item>
    
    <item>
      <title>New Website Theme!</title>
      <link>/post/new-website-theme/</link>
      <pubDate>Sat, 14 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/new-website-theme/</guid>
      <description>This post has needed to be writtend for a little while, but I&amp;rsquo;ve been busy with the actual work of redesigning my website (in fact, I have a number of posts that are backlogged). This post will have a little bit of code (all of it CSS, rather than R), but mostly it&amp;rsquo;s just about my journey and things I&amp;rsquo;ve learned.
Getting started with Blogdown In Yihui&amp;rsquo;s introduction to blogdown he advocates for simpler themes.</description>
    </item>
    
    <item>
      <title>Sharing some functions from my personal R package</title>
      <link>/post/sharing-some-functions-from-my-personal-r-package/</link>
      <pubDate>Sat, 10 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/sharing-some-functions-from-my-personal-r-package/</guid>
      <description>In this post I basically just wanted to share some recent developments that I&amp;rsquo;ve made to my personal R package {sundry}. All of the recent advancements have been made to work with the tidyverse, so things like group_by should work seamlessly. If you feel like giving the package a whirl, I&amp;rsquo;d love any feedback you have or bugs you may find. At this point the package is only on github. If there seems to be interest from others in using any of this functionality, I may submit it to CRAN.</description>
    </item>
    
    <item>
      <title>A tidyeval use case</title>
      <link>/post/a-tidyeval-use-case/</link>
      <pubDate>Tue, 09 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/a-tidyeval-use-case/</guid>
      <description>A relatively routine process for me is to combine multiple files into a single data frame by row. For example, the data might be stored in separate CSV files by grade and content area, but I want to load them all and treat it as a single data frame with a grade and content indicator. A good default for this sort of process, is to keep all the variables that are present in any data file, and pad with missingness for the files that don&amp;rsquo;t have that specific variable.</description>
    </item>
    
    <item>
      <title>esvis: Binned Effect Size Plots</title>
      <link>/post/esvis-binned-effect-size-plots/</link>
      <pubDate>Thu, 04 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/esvis-binned-effect-size-plots/</guid>
      <description>In this post, I&amp;rsquo;d like to share one of the more unique plots from esvis - the binned effect size plot. The overall purpose of the binned effect size plot is to evaluate if the differences between two distributions are consistent across the scale. We&amp;rsquo;ll start with a quick example from the package, and then move to a simulated data example.
Quick example The API for esvis is consistent across functions, so we use the same outcome ~ predictor forumula as the first argument, followed by the data for all functions.</description>
    </item>
    
    <item>
      <title>Alluvial Diagrams with ggforce</title>
      <link>/post/alluvial-plots-with-ggforce/</link>
      <pubDate>Wed, 29 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/alluvial-plots-with-ggforce/</guid>
      <description>Today I wanted to quickly share my first real attempt at making an alluvial diagram. For those not familiar (and I wasn&amp;rsquo;t previously) an alluvial diagram is a type of flow plot that is essentially equivalent to a sankey diagram. The difference is that while sankey diagrams show flow for different categorical variables, alluvial plots show change over time. To produce the alluvial diagram below, I&amp;rsquo;ll be using the development version of the excellent ggforce package written by Thomas Lin Pedersen, who&amp;rsquo;s not only incredibly talented, but also a good follow on twitter.</description>
    </item>
    
    <item>
      <title>Mapping Statewide School Ratings with US Census Tracts</title>
      <link>/post/mapping-statewide-school-ratings-with-us-census-tracts/</link>
      <pubDate>Mon, 13 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/mapping-statewide-school-ratings-with-us-census-tracts/</guid>
      <description>In this post, I&amp;rsquo;d like to share some work related to geo-spatial mapping, statewide school ratings, and US Census Bureau data using census tracts. Specifically, I wanted to investigate whether there was a relation between the median housing price in an area, and the statewide achievement ratings for schools in the corresponding area. There is a strong relation between socio-economic status and student achievement, but less is known about how statewide ratings for schools relate to the demographics of the corresponding area.</description>
    </item>
    
    <item>
      <title>esvis: Part 1</title>
      <link>/post/esvis-part-1/</link>
      <pubDate>Sun, 05 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/esvis-part-1/</guid>
      <description>This is the first of a series of posts to introduce my new esvis R package, why I think it&amp;rsquo;s important, and some of its capabilities. As of this writing the current version on CRAN is 0.0.1, so it&amp;rsquo;s obviously still fresh and may have some bugs. If you find any, please let me know. You can install the package like you would any other on R
install.packages(&amp;quot;esvis&amp;quot;)  or if you&amp;rsquo;d prefer the sometimes buggy but more feature-heavy development version, install from github with devtools.</description>
    </item>
    
  </channel>
</rss>